# HumanityHelper

## Goal

To build an open-source, lightweight language model that enables the wider community to run an intelligent AI assistant locally.

## Objectives

- Leverage current language model (LLM/SLM) architectures and training techniques
- Utilize a mixture of experts approach with 3-5 specialized expert models (math, Science, ...)
- Optimize the model to be computationally efficient, allowing it to run on consumer-grade hardware (GPU,CPU,Embeded)
- Provide clear documentation and tutorials to make the model accessible to developers of varying skill levels
- Implement a markdown-based input and output format for enhanced readability and structure
- Engage the community to contribute to the model's ongoing development and improvement

## Milestones

1. Research and select the most suitable LLM architecture and training approaches
2. Design the mixture of experts system and define the specialties of each expert model
3. Collect and preprocess diverse training data for each expert [DATA](DATA.md)
4. Train the individual expert models and the gating network
5. Optimize the model for computational efficiency and local deployment
6. Implement the markdown input/output interface
7. Write comprehensive documentation and tutorials
8. Release an initial version to the community for testing and feedback
9. Incorporate community input and contributions
10. Launch a stable release of HumanityHelper

By providing a detailed goal statement with clear objectives and milestones, the project has a well-defined roadmap. This makes it more likely to succeed in its mission of empowering the broader community with accessible, locally-run AI language model technology.
